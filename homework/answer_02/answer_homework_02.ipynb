{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "#x.shape = (3,1)\n",
    "\n",
    "x1,x2,x3 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "First we define a test function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x0 = np.reshape(np.array([1.0, 1.4]),(2,1))\n",
    "\n",
    "\n",
    "test = lambda x: np.reshape(np.array([x[0,0]**2-x[0,0]-1.0, np.log(3.0*x[1,0]**2-x[0,0])]),(2,1))\n",
    "\n",
    "gtest = lambda x: np.array([ [2.0*x[0,0]-1.0, 0.0],\n",
    "                             [-1./(x[1,0]**2-x[0,0]), 6.0*x[1,0]/(3.0*x[1,0]**2-x[0,0])]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define them so that they take an np.array as input and return np.array as output. Hence, I take it for granted that both f and g are np.array-valued functions in the Newton-Raphson method routine below. However, as you can see, the definition of the functions are not very cute. \n",
    "\n",
    "An alternative approach would be to allow these functions to be \"array-like\"-valued, and then define the Newton-Raphson routine so that it convert them into np.array's. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NRmethodm(f,g,x0, xtol=1e-6, ftol=1e-6, max_iter=1000):\n",
    "    \n",
    "    # Newton-Raphson method for a vector-valued function\n",
    "    # f: function\n",
    "    # g: Jacobian function\n",
    "    # x0: initial condition\n",
    "    \n",
    "    x, fx, gx = x0, f(x0), g(x0)\n",
    "    \n",
    "    xp = np.empty_like(x)\n",
    "    \n",
    "    i_iter = 0\n",
    "    \n",
    "\n",
    "    while i_iter<=max_iter:\n",
    "        i_iter += 1\n",
    "        \n",
    "        dx = - np.linalg.solve(gx,fx)\n",
    "        xp = x+dx\n",
    "        \n",
    "        x[:], fx[:], gx[:] = xp, f(xp), g(xp)        \n",
    "        \n",
    "        print('Iteration step n = ' + str(i_iter) + ', x[n+1] (transposed) = ' + str(x.T))\n",
    "        \n",
    "        if np.linalg.norm(dx,np.inf) <= xtol*(1+np.linalg.norm(x,np.inf)):\n",
    "            break\n",
    "\n",
    "    if i_iter == max_iter:\n",
    "        print('Max. number of iteration reached. A solution may not be accurate.')\n",
    "        return x\n",
    "    elif np.linalg.norm(fx,np.inf)<=ftol: \n",
    "        print('Newton-Raphson method converged.')\n",
    "        return x\n",
    "    else:\n",
    "        print('Newton-Raphson method failed to find a solution.')\n",
    "        return x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration step n = 1, x[n+1] (transposed) = [[ 2.          1.08426484]]\n",
      "Iteration step n = 2, x[n+1] (transposed) = [[ 1.66666667  1.07983264]]\n",
      "Iteration step n = 3, x[n+1] (transposed) = [[ 1.61904762  0.93567165]]\n",
      "Iteration step n = 4, x[n+1] (transposed) = [[ 1.61803445  0.93459376]]\n",
      "Iteration step n = 5, x[n+1] (transposed) = [[ 1.61803399  0.93417215]]\n",
      "Iteration step n = 6, x[n+1] (transposed) = [[ 1.61803399  0.93417236]]\n",
      "Newton-Raphson method converged.\n",
      "\n",
      "Evaluate the test function at the computed solution. (Transposed)\n",
      "[[  0.00000000e+00  -3.40172335e-13]]\n"
     ]
    }
   ],
   "source": [
    "sol = NRmethodm(test,gtest,x0)\n",
    "\n",
    "print('')\n",
    "print('Evaluate the test function at the computed solution. (Transposed)')\n",
    "print(test(sol).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "Using the parameter values and the functional form assumptions, we can write the Euler equation as:\n",
    "\n",
    "$$ 0 = f(x; \\epsilon) := \\epsilon \\frac{1-x}{x} + (1-\\epsilon)\\frac{1-x}{\\frac{1}{1-\\epsilon}+ x}-1.$$\n",
    "\n",
    "$$ \\frac{\\partial f(x;\\epsilon)}{\\partial x} = -\\frac{\\epsilon}{x^2} - \\frac{2-\\epsilon}{(\\frac{1}{1-\\epsilon}+ x)^2}.$$\n",
    "\n",
    "We have $n=91$ values of $\\epsilon$, $\\{\\epsilon_i\\}_{i=1}^n$, and want to solve\n",
    "\n",
    "$$ 0= f(x_i;\\epsilon_i)$$\n",
    "\n",
    "for all $i=1,2,...,n$. \n",
    "\n",
    "Of course we can obtain a solution $\\{x_i\\}_{i=1}^n$ by solving a univariate root-finding problem for $n=91$ times. This is a brute-force method.\n",
    "\n",
    "One way to speed up a brute-force method is to use a solution to the $(i-1)$-th problem as the initial condition for the $i$-th problem, because we expect that solutions are close if $\\epsilon$'s are close. This is called a \"warm start\" as opposed to a \"cold-start,\" which sets the initial condition independent of previous computation results. \n",
    "\n",
    "We can, however, solve for all $\\{x_i\\}_{i=1}^n$ **at once**. Note that a Newton iterate at step $k$ for each $i$ takes the form:\n",
    "\n",
    "$$ x_i(k+1) = g_i(x_i(k)) := x_i(k) - \\frac{\\partial f(x_i(k);\\epsilon_i)}{\\partial x}f(x_i(k);\\epsilon_i).$$\n",
    "\n",
    "Hence by defining\n",
    "\n",
    "$$ \\textbf{x} = \\left[\\begin{array}{c}\n",
    "\t\t\t\tx_1\\\\\n",
    "\t\t\t\tx_2\\\\\n",
    "\t\t\t\t\\vdots\\\\\n",
    "\t\t\t\tx_n\n",
    "\t\t\t\t\\end{array}\\right],$$\n",
    "\n",
    "$$ \\textbf{e} = \\left[\\begin{array}{c}\n",
    "\t\t\t\t\\epsilon_1\\\\\n",
    "\t\t\t\t\\epsilon_2\\\\\n",
    "\t\t\t\t\\vdots\\\\\n",
    "\t\t\t\t\\epsilon_n\n",
    "\t\t\t\t\\end{array}\\right],$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ G(\\mathbf{x};\\mathbf{e}) = \\left[\\begin{array}{c}\n",
    "\t\t\t\tg_1(x_1)\\\\\n",
    "\t\t\t\tg_2(x_2)\\\\\n",
    "\t\t\t\t\\vdots\\\\\n",
    "\t\t\t\tg_n(x_n)\n",
    "\t\t\t\t\\end{array}\\right],$$\n",
    "                \n",
    "we can do a fixed-point iteration for a vector-valued function $G$:\n",
    "\n",
    "$$ \\textbf{x}(k+1) = G(\\textbf{x}(k);\\mathbf{e}).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed =  0.0016544379759579897  sec.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDNXG8SZk4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee27828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNzMrQ07uZmZl6P8DHlB95h/1JxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11219d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n = 91\n",
    "eps_v = np.reshape(np.linspace(0.0,0.9,num=n), (n,1))   # vector of epsilon's\n",
    "x0 = np.zeros_like(eps_v)+0.01 # initial condition\n",
    "\n",
    "\n",
    "G = lambda x,e: x- ((-e/(x**2)-(2-e)/((1.0/(1-e)+x)**2)))**(-1)*((e*(1.0/x-1.)+(1-e)*(1.0-x)/(1.0/(1-e)+x))-1.0)\n",
    "\n",
    "\n",
    "max_iter = 1000\n",
    "xtol = 1.0e-8\n",
    "\n",
    "i_iter = 0\n",
    "\n",
    "xp = np.empty_like(x0)\n",
    "x = np.empty_like(x0)\n",
    "x[:] = x0\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while i_iter<=max_iter:\n",
    "    xp[:] = G(x,eps_v)\n",
    "\n",
    "    if np.linalg.norm(xp-x,np.inf) <= xtol*(1+np.linalg.norm(x,np.inf)):\n",
    "            break\n",
    "    x[:] = xp\n",
    "    i_iter += 1\n",
    "\n",
    "if i_iter == max_iter:\n",
    "    print('Max. number of iteration reached. A solution may not be accurate.')\n",
    "\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "   \n",
    "print('Time elapsed = ', end_time-start_time, ' sec.')    \n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(eps_v, x, 'b-', linewidth=1, label='Saving function')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_title('Saving function')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(eps_v, G(x,eps_v)-x, 'b-', linewidth=1, label='Euler equation error')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_title('Euler equation error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.68439678e-17],\n",
       "       [  6.61956363e-02],\n",
       "       [  9.13252487e-02],\n",
       "       [  1.09847895e-01],\n",
       "       [  1.25000000e-01],\n",
       "       [  1.38026263e-01],\n",
       "       [  1.49560874e-01],\n",
       "       [  1.59978236e-01],\n",
       "       [  1.69520847e-01],\n",
       "       [  1.78356181e-01],\n",
       "       [  1.86605497e-01],\n",
       "       [  1.94359845e-01],\n",
       "       [  2.01689593e-01],\n",
       "       [  2.08650415e-01],\n",
       "       [  2.15287228e-01],\n",
       "       [  2.21636875e-01],\n",
       "       [  2.27729999e-01],\n",
       "       [  2.33592404e-01],\n",
       "       [  2.39246049e-01],\n",
       "       [  2.44709800e-01],\n",
       "       [  2.50000000e-01],\n",
       "       [  2.55130913e-01],\n",
       "       [  2.60115073e-01],\n",
       "       [  2.64963562e-01],\n",
       "       [  2.69686232e-01],\n",
       "       [  2.74291885e-01],\n",
       "       [  2.78788425e-01],\n",
       "       [  2.83182976e-01],\n",
       "       [  2.87481988e-01],\n",
       "       [  2.91691321e-01],\n",
       "       [  2.95816316e-01],\n",
       "       [  2.99861860e-01],\n",
       "       [  3.03832435e-01],\n",
       "       [  3.07732163e-01],\n",
       "       [  3.11564848e-01],\n",
       "       [  3.15334006e-01],\n",
       "       [  3.19042897e-01],\n",
       "       [  3.22694550e-01],\n",
       "       [  3.26291782e-01],\n",
       "       [  3.29837224e-01],\n",
       "       [  3.33333333e-01],\n",
       "       [  3.36782411e-01],\n",
       "       [  3.40186616e-01],\n",
       "       [  3.43547975e-01],\n",
       "       [  3.46868399e-01],\n",
       "       [  3.50149686e-01],\n",
       "       [  3.53393534e-01],\n",
       "       [  3.56601549e-01],\n",
       "       [  3.59775250e-01],\n",
       "       [  3.62916079e-01],\n",
       "       [  3.66025404e-01],\n",
       "       [  3.69104523e-01],\n",
       "       [  3.72154675e-01],\n",
       "       [  3.75177037e-01],\n",
       "       [  3.78172734e-01],\n",
       "       [  3.81142839e-01],\n",
       "       [  3.84088378e-01],\n",
       "       [  3.87010334e-01],\n",
       "       [  3.89909648e-01],\n",
       "       [  3.92787222e-01],\n",
       "       [  3.95643924e-01],\n",
       "       [  3.98480585e-01],\n",
       "       [  4.01298008e-01],\n",
       "       [  4.04096965e-01],\n",
       "       [  4.06878199e-01],\n",
       "       [  4.09642428e-01],\n",
       "       [  4.12390347e-01],\n",
       "       [  4.15122624e-01],\n",
       "       [  4.17839910e-01],\n",
       "       [  4.20542833e-01],\n",
       "       [  4.23232002e-01],\n",
       "       [  4.25908009e-01],\n",
       "       [  4.28571429e-01],\n",
       "       [  4.31222819e-01],\n",
       "       [  4.33862724e-01],\n",
       "       [  4.36491673e-01],\n",
       "       [  4.39110183e-01],\n",
       "       [  4.41718758e-01],\n",
       "       [  4.44317891e-01],\n",
       "       [  4.46908062e-01],\n",
       "       [  4.49489743e-01],\n",
       "       [  4.52063396e-01],\n",
       "       [  4.54629473e-01],\n",
       "       [  4.57188419e-01],\n",
       "       [  4.59740670e-01],\n",
       "       [  4.62286655e-01],\n",
       "       [  4.64826798e-01],\n",
       "       [  4.67361515e-01],\n",
       "       [  4.69891215e-01],\n",
       "       [  4.72416305e-01],\n",
       "       [  4.74937185e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, depending on the initial condition, we may encounter the limited domain problem for this problem. (This is not specific to the fixed point iteration. Even if you solve root-finding problems for each $i$, you may encounter that.)\n",
    "\n",
    "The brute-force approach using the bisection method is more robust, but must take longer to converge. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Q3\n",
    "\n",
    "We try to find a minimizer of \n",
    "\\begin{eqnarray*}\n",
    "f(x) = \\left\\{ \\begin{array}{lc}\n",
    "\t\t\t\t\\ln x & \\mbox{ if $x\\ge 1$, and}\\\\\n",
    "\t\t\t\t\\frac{1}{2}(x^2-1) & \\mbox{ if $x < 1$.}\n",
    "\t\t\t\t\\end{array}\\right. ,\n",
    "\\end{eqnarray*}\n",
    "which is $x=0$.\n",
    "\n",
    "\n",
    "Consider sequences $\\{x_n\\}$, $\\{p_n\\}$, and $\\{\\alpha_n\\}$ such that\n",
    "\n",
    "- $p_n = -1$ for all $n=0,1,...$;\n",
    "- $\\alpha_n = \\frac{1}{2^{n+1}}$ for all $n=0,1,...$; and\n",
    "- $x_0=2$ and $x_{n+1} = x_n +\\alpha_n p_n$ for $n=0,1,...$. \n",
    "\n",
    "### (1) $x_n \\in (1,2]$ for all $n$\n",
    "\n",
    "$x_{n+1} = x_n -\\frac{1}{2^{n+1}} = x_0 - \\sum_{i=1}^{n+1} \\frac{1}{2^{i}} = 2- \\sum_{i=1}^{n+1} \\frac{1}{2^{i}}.$\n",
    "\n",
    "Because, for any finite $n$, \n",
    "\n",
    "$$ 0< \\sum_{i=1}^{n+1} \\frac{1}{2^{i}} <\\sum_{i=1}^{\\infty} \\frac{1}{2^{i}} = 1,$$\n",
    "\n",
    "it follows that $x_n \\in (1,2]$ for all $n$.\n",
    "\n",
    "### (2) $x_n \\downarrow 1$ as $n\\rightarrow \\infty$\n",
    "\n",
    "This is obvious because $\\sum_{i=1}^{n+1} \\frac{1}{2^{i}}$ is increasing in $n$ and $\\sum_{i=1}^{n+1} \\frac{1}{2^{i}} \\rightarrow 1$ as $n\\rightarrow \\infty$. \n",
    "\n",
    "### (3) the first Wolfe condition is satisfied for all $n$. (Hint: $f$ is a concave function for $x\\ge 1$.)\n",
    "\n",
    "Because $x_n \\in (1,2]$ for all $n$, \n",
    "\n",
    "$$ f(x_n) = \\ln x_n$$\n",
    "\n",
    "for all $n$. \n",
    "\n",
    "Because $f$ is a concave function on $[1,2]$, \n",
    "\n",
    "$$ f(x_{n+1}) < f(x_n) + f'(x_n)(x_{n+1}-x_n) = f(x_n) -f'(x_n)\\alpha_n. $$\n",
    "\n",
    "On the other hand, the first Wolfe condition for the single dimensional function $f$ is \n",
    "\n",
    "$$ f(x_{n+1}) \\le f(x_n) +c_1 \\alpha_n p_n f'(x_n) = f(x_n) -c_1 \\alpha_n f'(x_n) $$\n",
    "\n",
    "for small $c_1 \\in (0,1)$. Because $f'>0$ on $[1,2]$, \n",
    "\n",
    "$$ f(x_{n+1}) < f(x_n) + f'(x_n)(x_{n+1}-x_n) = f(x_n) -f'(x_n)\\alpha_n < f(x_n) -c_1 \\alpha_n f'(x_n). $$\n",
    "\n",
    "Hence the first Wolfe condition is automatically satisfied. \n",
    "\n",
    "### What happens when we impose the second condition\n",
    "\n",
    "The second Wolfe condition requires \n",
    "\n",
    "$$ -f'(x_1) \\ge -c_2 f'(x_0) $$\n",
    "\n",
    "for $c_2 \\in (c_1,1)$.\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$ -f'(x_1) \\ge -c_2 \\frac{1}{2} \\Rightarrow f'(x_1) \\le \\frac{c_2}{2} $$\n",
    "\n",
    "for $c_2 \\in (c_1,1)$.\n",
    "\n",
    "Given the search direction $p_0 = -1$, we have to have $x_1 < x_0 = 2$. The derivative of $f$ at $x_1$ can be less than or equal to $c_2/2$ if and only if\n",
    "\n",
    "$$ x_1 \\le {\\frac{c_2}{2}}. $$\n",
    "\n",
    "The maximal value $x_1 = x_0+\\alpha_0 p_0$ can take is therefore ${\\frac{c_2}{2}}$.\n",
    "\n",
    "\n",
    "As you can see, the second Wolfe condition requires you to take a larger step and it prevents us from getting stuck at a point that is not a local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.49999999990997734\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "-----\n",
      "     fun: -0.49999999990997734\n",
      "     jac: array([  1.00001342e+00,  -5.00000000e-01,  -5.27197904e-16,\n",
      "        -5.00000000e-01])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 8\n",
      "     nit: 8\n",
      "    njev: 8\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([  1.00001342e+00,   2.00002684e+00,  -5.27197904e-16,\n",
      "        -4.37563776e-16])\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize \n",
    "\n",
    "thetaH = 2.0\n",
    "thetaL = 1.0\n",
    "UH = 0.0\n",
    "UL = 0.0\n",
    "\n",
    "# x = (qH,pH,qL,pL)\n",
    "\n",
    "def cost(x):\n",
    "    return 0.5*(x[0]**2-x[1] + x[2]**2 - x[3]) # Expected cost = 0.5*( qH^2-pH + qL^2-pL )\n",
    "\n",
    "\n",
    "def cost_der(x):\n",
    "    g = np.zeros_like(x)\n",
    "    g[0] = x[0]\n",
    "    g[1] = -0.5\n",
    "    g[2] = x[2]\n",
    "    g[3] = -0.5\n",
    "    return g\n",
    "\n",
    "def const(x):\n",
    "    c = np.zeros(4)\n",
    "    c[0] =thetaH*x[0]-x[1]-UH # individual rationality for H\n",
    "    c[1] =thetaL*x[2]-x[3]-UL # individual rationality for L\n",
    "    c[2] =thetaH*x[0]-x[1]-(thetaH*x[2]-x[3]) # Incentive compatibility for H\n",
    "    c[3] =thetaL*x[2]-x[3]-(thetaL*x[0]- x[1]) # Incentive compatibility for L\n",
    "    return c\n",
    "\n",
    "def const_jac(x):\n",
    "    jac = np.array([[thetaH, -1.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, thetaL, -1.0],\n",
    "                    [thetaH, -1.0, -thetaH, 1.0],\n",
    "                    [-thetaL, 1.0, thetaL, -1.0]])\n",
    "    return jac\n",
    "\n",
    "\n",
    "cons = ({'type': 'ineq', 'fun': const, 'jac': const_jac})\n",
    "\n",
    "res = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "                    \n",
    "print('-----')\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is separating. The H type faces higher price and higher quality than does the L type.\n",
    "\n",
    "To see which constraints are not binding, let us evaluate the constraint function at the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Constraint evaluated at the solution\n",
      "[  2.22044605e-15  -8.96341288e-17   2.83727808e-15   1.00001342e+00]\n"
     ]
    }
   ],
   "source": [
    "print('-----')\n",
    "print('Constraint evaluated at the solution')\n",
    "print(const(res.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last value is different from zero, so the IC for the L type is slack.\n",
    "\n",
    "The remaining values are close to zero, but they may happen to be so. \n",
    "\n",
    "To check whether they are binding or not, we can either relax or tighten each of these constraints to examine whether the solution changes or not.\n",
    "\n",
    "First the IR constraint for L. This constraint is binding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.594999999665983\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "\n",
      "Solution when UL= -0.1\n",
      "[ 1.00002585  2.00005169  0.1         0.2       ]\n",
      "Changes in the solution\n",
      "[  1.24283166e-05   2.48566332e-05   1.00000000e-01   2.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "UL = -0.1\n",
    "\n",
    "res1 = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "\n",
    "print('')\n",
    "print('Solution when UL=', UL)\n",
    "print(res1.x)\n",
    "print('Changes in the solution')\n",
    "print(res1.x-res.x)\n",
    "\n",
    "UL = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the IC constraint for H. I add 0.1 to the LHS of the IC for H to relax the constraint. \n",
    "\n",
    "This constraint is also binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.5450000000000005\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "\n",
      "Solution when the IC is relaxed\n",
      "[ 1.   2.   0.1  0.1]\n",
      "Changes in the solution\n",
      "[ -1.34179968e-05  -2.68359936e-05   1.00000000e-01   1.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def const2(x):\n",
    "    c = np.zeros(4)\n",
    "    c[0] =thetaH*x[0]-x[1]-UH # individual rationality for H\n",
    "    c[1] =thetaL*x[2]-x[3]-UL # individual rationality for L\n",
    "    c[2] =thetaH*x[0]-x[1]-(thetaH*x[2]-x[3])+0.1 # Incentive compatibility for H\n",
    "    c[3] =thetaL*x[2]-x[3]-(thetaL*x[0]- x[1]) # Incentive compatibility for L\n",
    "    return c\n",
    "\n",
    "cons2 = ({'type': 'ineq', 'fun': const2, 'jac': const_jac})\n",
    "res2 = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons2, options={'disp': True, 'ftol': 1.0e-8})\n",
    "\n",
    "print('')\n",
    "print('Solution when the IC is relaxed')\n",
    "print(res2.x)\n",
    "print('Changes in the solution')\n",
    "print(res2.x-res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the IR for the H type is slack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.49999999920423527\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "\n",
      "Solution when UH= -0.1\n",
      "[  1.00002180e+00   2.00007701e+00  -3.34137913e-05  -3.34137913e-05]\n",
      "Changes in the solution\n",
      "[  8.37764229e-06   5.01690759e-05  -3.34137913e-05  -3.34137913e-05]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UH = -0.1\n",
    "\n",
    "res3 = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "\n",
    "print('')\n",
    "print('Solution when UH=', UH)\n",
    "print(res3.x)\n",
    "print('Changes in the solution')\n",
    "print(res3.x-res.x)\n",
    "\n",
    "UH = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is natural. If both the IR and the IC for the H type are slack, then the seller can increase her profit by raising the price for the H type. So either one of them has to be binding. In this example, UH is sufficiently low and the IR is slack for the H type. Hence the IC for the H type binds. \n",
    "\n",
    "In sum, the IC for the H type and the IR for the L type bind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us raise $\\theta_H$.\n",
    "\n",
    "Higher $\\theta_H$ implies that the H type is willing to pay more for the same quality. This allows the seller to achieve higher profit by increasing the quality qH and the price pH. The effects on qL and pL are small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1.1249999999999982\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "\n",
      "Solution when thetaH= 3.0\n",
      "[  1.50000000e+00   4.50000000e+00  -4.00377834e-16   1.19282891e-17]\n",
      "Changes in the solution\n",
      "[  4.99986582e-01   2.49997316e+00   1.26820071e-16   4.49492065e-16]\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -4.499999999999968\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "\n",
      "Solution when thetaH= 6.0\n",
      "[  3.00000000e+00   1.80000000e+01  -4.29176500e-15  -3.09108869e-15]\n",
      "Changes in the solution\n",
      "[  1.99998658e+00   1.59999732e+01  -3.76456710e-15  -2.65352492e-15]\n"
     ]
    }
   ],
   "source": [
    "thetaH = 3.0\n",
    "\n",
    "res_high_thetaH = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "                    \n",
    "print('')\n",
    "print('Solution when thetaH=', thetaH)\n",
    "print(res_high_thetaH.x)\n",
    "print('Changes in the solution')\n",
    "print(res_high_thetaH.x-res.x)\n",
    "\n",
    "thetaH = 6.0\n",
    "\n",
    "res_high_thetaH = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "                    \n",
    "print('')\n",
    "print('Solution when thetaH=', thetaH)\n",
    "print(res_high_thetaH.x)\n",
    "print('Changes in the solution')\n",
    "print(res_high_thetaH.x-res.x)\n",
    "\n",
    "thetaH = 2.0 # original value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now turn to $U_H$. \n",
    "\n",
    "Although the IR for the H type was slack in the original setting, it may bind for higher $U_H$. \n",
    "\n",
    "What happens below is that, when UH is raised to 1.0, the IR for the H types is binding. The IR for the L type is still satisfied (almost) with equality, but the IC for the L types starts binding while that for the H type becomes slack.\n",
    "\n",
    "When UH is raised further to 2.0, the IR for the L type becomes slack. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.1249999999993941\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "\n",
      "Solution when UH= 1.0\n",
      "[ 1.         1.         0.5000011  0.5000011]\n",
      "Changes in the solution\n",
      "[  1.99998658e+00   1.59999732e+01  -3.76456710e-15  -2.65352492e-15]\n",
      "Constraint evaluated at the solution\n",
      "[  1.77635684e-15   9.99200722e-16   4.99998900e-01  -8.88178420e-16]\n",
      "\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.7500000000689266\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "\n",
      "Solution when UH= 2.0\n",
      "[  1.50000974e+00   1.00001948e+00   5.00006555e-01   1.62957742e-05]\n",
      "Changes in the solution\n",
      "[  4.99996323e-01  -1.00000735e+00   5.00006555e-01   1.62957742e-05]\n",
      "Constraint evaluated at the solution\n",
      "[  8.88178420e-16   4.99990259e-01   1.00000319e+00  -7.77156117e-16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UH = 1.0\n",
    "\n",
    "res_high_UH = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "                    \n",
    "print('')\n",
    "print('Solution when UH=', UH)\n",
    "print(res_high_UH.x)\n",
    "print('Changes in the solution')\n",
    "print(res_high_thetaH.x-res.x)\n",
    "print('Constraint evaluated at the solution')\n",
    "print(const(res_high_UH.x))\n",
    "print('')\n",
    "\n",
    "UH = 2.0\n",
    "\n",
    "res_high_UH = optimize.minimize(cost, [0., 0., 0., 0.], jac=cost_der, method='SLSQP', \n",
    "                        constraints=cons, options={'disp': True, 'ftol': 1.0e-8})\n",
    "                    \n",
    "print('')\n",
    "print('Solution when UH=', UH)\n",
    "print(res_high_UH.x)\n",
    "print('Changes in the solution')\n",
    "print(res_high_UH.x-res.x)\n",
    "print('Constraint evaluated at the solution')\n",
    "print(const(res_high_UH.x))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
