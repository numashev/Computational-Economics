{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "A good reference is Jorge Nocedal and Stephen J. Wright, _Numerical Optimization_, Second ed., Springer.\n",
    "\n",
    "\n",
    "We will use SciPy optimization routines, so let us first import it. \n",
    "\n",
    "Unlike NumPy, we do not import the whole SciPy. Here we specifically import _optimize_ from SciPy. <https://docs.scipy.org/doc/scipy/reference/api.html#guidelines-for-importing-functions-from-scipy>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize \n",
    "import numpy as np # We will use numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest optimization problem is an _unconstrained optimization_ that is formulated as\n",
    "\n",
    "$$ \\min_{x\\in \\mathbb{R}^N} f(x).$$\n",
    "\n",
    "(Without loss of generality, we focus on minimization problems; maximizing $f$ is the same as minimizing $-f$.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function $f$ is convex and differentiable, finding a minimizer is the same as finding the root of $f'$. But in general $f$ may have local minimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly speaking, there are two strategies to generate a sequence of candidate solution $\\{x_n\\}$. \n",
    "\n",
    "In the **line search** strategy, the algorithm first chooses a search direction, $p_n$, toward which the iterate $x_n$ is updated, and the step size $\\alpha$ is chosen so as to \"loosely\" minimize\n",
    "\n",
    "$$ \\phi(\\alpha) := f(x_n + \\alpha p_n).$$\n",
    "\n",
    "Minimizing this function exactly is costly, so $\\alpha$ is chosen so that\n",
    "\n",
    "1. $f$ decreases sufficiently, and\n",
    "2. $\\phi'(\\alpha)$ is not too negative (or it is close to zero, or $\\alpha$ is not too small).  \n",
    "\n",
    "Algorithms are differnt in their way to choose the search direction. The steepest descent method uses\n",
    "\n",
    "$$ p_n = -  \\nabla f(x_n),$$\n",
    "\n",
    "the Newton's method uses\n",
    "\n",
    "$$ p_n = -  (\\nabla^2 f(x_n))^{-1}\\nabla f(x_n),$$\n",
    "\n",
    "where $\\nabla^2 f(x_n)$ is the Hessian, and quasi-Newton methods use\n",
    "\n",
    "$$ p_n = -  B_n^{-1}\\nabla f(x_n),$$\n",
    "\n",
    "where $B_n$ is an approximation to the Hessian. The BFGS method is a quasi-Newton method.\n",
    "\n",
    "\n",
    "The other strategy is the **trust-region** strategy. At each $n$, it approximates $f$ in a neighborhood of $x_n$ (or, in a \"trust region\") and then find the candidate step by solving\n",
    "\n",
    "$$ \\min_p m_n(x_n+p)$$\n",
    "\n",
    "where $x_n+p$ lies inside the trust region. Usually $p^T p<\\Delta$ is used for a trust region. In the trust-region method, therefore, both the direction and the step size are simultaneously determined.\n",
    "\n",
    "The model $m_n$ is usually a quadratic function of the form:\n",
    "\n",
    "$$ m_n(x_n+p) = f(x_n) + p^T \\nabla f(x_n) + \\frac{1}{2}p^T B_n p. $$\n",
    "\n",
    "The matrix $B_n$ is either the Hessian or some approximation to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A usual test function is the Rosenbrock function. \n",
    "\n",
    "SciPy has it, along with its gradient and Hessian functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 26\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 31\n",
      "-----\n",
      "      fun: 1.4759786947522541e-15\n",
      " hess_inv: array([[ 0.00763624,  0.0125159 ,  0.02359808,  0.0465684 ,  0.09317974],\n",
      "       [ 0.0125159 ,  0.02489687,  0.04727754,  0.09353774,  0.18708048],\n",
      "       [ 0.02359808,  0.04727754,  0.09483095,  0.18783847,  0.37561493],\n",
      "       [ 0.0465684 ,  0.09353774,  0.18783847,  0.37715312,  0.75414172],\n",
      "       [ 0.09317974,  0.18708048,  0.37561493,  0.75414172,  1.51296479]])\n",
      "      jac: array([  9.93918700e-07,   4.21980188e-07,   2.23775033e-07,\n",
      "        -6.10304485e-07,   1.34057054e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 31\n",
      "      nit: 26\n",
      "     njev: 31\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.,  1.,  1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "\n",
    "# BFGS method\n",
    "res = optimize.minimize(optimize.rosen, x0, method='BFGS',\n",
    "               jac=optimize.rosen_der,\n",
    "               options={'gtol': 1e-6, 'disp': True})\n",
    "\n",
    "print('-----')\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy.optimize.minimize() function has methods that are not derivative-based. One example is the Nelder-Mead revised simplex method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "\n",
    "# Nelder-Mead method\n",
    "res = optimize.minimize(optimize.rosen, x0, method='Nelder-Mead',\n",
    "               options={'xtol': 1e-8,'disp': True})\n",
    "\n",
    "print('-----')\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained optimization\n",
    "\n",
    "A general constrained minimization problem is given by:\n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^N} f(x) $$\n",
    "\n",
    "subject to:\n",
    "\n",
    "1. Equality constraints: for $i\\in \\mathcal{E}$, $ c_i(x) = 0$, and\n",
    "\n",
    "2. Inequality constraints: for $i\\in \\mathcal{I}$, $c_i(x) \\le 0$.\n",
    "\n",
    "(We may separately have the bound constraints, $lb \\le x \\le ub$.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear programming\n",
    "\n",
    "When both objective and all constraint functions are linear in x, the problem can be written as \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^N} c^T x $$\n",
    "\n",
    "subject to:\n",
    "\n",
    "1. Equality constraints: $A_{eq}x = b_{eq}$, and\n",
    "\n",
    "2. Inequality constraints:  $A_{ub}x \\le b_{ub}$.\n",
    "\n",
    "The SciPy routine _scipy.optimize.linprog()_ also takes the bound constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear programming example\n",
    "\n",
    "Consider the following example taken from the documentation: <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html>\n",
    "\n",
    "$x \\in \\mathbb{R}^2$.\n",
    "\n",
    "\n",
    "Minimize: $-x[0] + 4x[1]$\n",
    "\n",
    "Subject to: \n",
    "\\begin{eqnarray}\n",
    "-3x[0] + x[1] &\\le& 6\\\\\n",
    "x[0] + 2x[1] &\\le & 4\\\\\n",
    "x[1] &\\ge& -3.\n",
    "\\end{eqnarray}\n",
    "\n",
    "There is no bound constraint for $x[0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -22.000000  \n",
      "         Iterations: 1\n",
      "-------\n",
      "     fun: -22.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 1\n",
      "   slack: array([ 39.,   0.])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 10.,  -3.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameter specification\n",
    "c = [-1, 4]\n",
    "A = [[-3, 1], [1, 2]]\n",
    "b = [6, 4]\n",
    "x0_bounds = (None, None)   # None is used to mean \"no constraint\"\n",
    "x1_bounds = (-3, None)\n",
    "\n",
    "# Call optimize.linprog\n",
    "res = optimize.linprog(c, A_ub=A, b_ub=b, bounds=(x0_bounds, x1_bounds),\n",
    "              options={\"disp\": True})\n",
    "\n",
    "print('-------')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, _linprog_ returns an object that contains all kinds of information. To see the solution only, we can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic programming\n",
    "\n",
    "The general quadratic problem (QP) is stated as:\n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^N} x^T G x + x^Tc $$\n",
    "\n",
    "subject to:\n",
    "\n",
    "1. Equality constraints: $A_{eq}x = b_{eq}$, and\n",
    "\n",
    "2. Inequality constraints:  $A_{ub}x \\le b_{ub}$.\n",
    "\n",
    "When $G$ is a positive semi-definite, the problem is called a convex QP.\n",
    "\n",
    "Problems of this class can be solved in a finite amount of computation. For example, in the absence of inequality constraints, the first-order necessary conditions are linear and, hence, finding a stationary point of the Lagrangian amounts to solving a system of linear equations. \n",
    "\n",
    "### Sequential quadratic programming\n",
    "\n",
    "Sequential quadratic programming generates a sequence $\\{x_n\\}$ by, for each $n$, solving a QP whose objective function quadratically approximates the Lagrangian and constraints linearly approximate the original constraint around $x_n$, to determine the search direction. The step size may be determined by line search. \n",
    "\n",
    "In SciPy, this can be used by calling scipy.optimize.minimize() by setting a keyword argument _method = 'SLSQP'_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example is taken from <https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html>:\n",
    "\n",
    "$$ \\max_{x,y} f(x, y) = 2 x y + 2 x - x^2 - 2 y^2$$\n",
    "\n",
    "subject to \n",
    "\n",
    "\\begin{eqnarray}\n",
    "x^3−y &=&0\\\\\n",
    "y−1 &\\ge &0\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, sign=1.0):\n",
    "    \"\"\" Objective function \"\"\"\n",
    "    return sign*(2*x[0]*x[1] + 2*x[0] - x[0]**2 - 2*x[1]**2)\n",
    "\n",
    "# When minimizing, sign=-1.0 will be specified.\n",
    "\n",
    "def func_deriv(x, sign=1.0):\n",
    "    \"\"\" Derivative of objective function \"\"\"\n",
    "    dfdx0 = sign*(-2*x[0] + 2*x[1] + 2)\n",
    "    dfdx1 = sign*(2*x[0] - 4*x[1])\n",
    "    return np.array([ dfdx0, dfdx1 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraint must be supplied in the form of _dictionary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq',\n",
    "         'fun' : lambda x: np.array([x[0]**3 - x[1]]),\n",
    "         'jac' : lambda x: np.array([3.0*(x[0]**2.0), -1.0])},\n",
    "        {'type': 'ineq',\n",
    "         'fun' : lambda x: np.array([x[1] - 1]),\n",
    "         'jac' : lambda x: np.array([0.0, 1.0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = optimize.minimize(func, [-1.0,1.0], args=(-1.0,), jac=func_deriv, method='SLSQP', options={'disp': True})\n",
    "\n",
    "print('-----')\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Lagrangian method\n",
    "\n",
    "Though not implemented in SciPy.optimize, the Augmented Lagrangian method is available in e.g. NLopt <http://ab-initio.mit.edu/wiki/index.php/NLopt> For installation via conda, see <https://anaconda.org/conda-forge/nlopt>.\n",
    "\n",
    "The basic idea behind it can be intuitively understood by studying the penalty function method first.\n",
    "\n",
    "### Penalty function approach\n",
    "\n",
    "Quite obviously, unconstrained optimization is much simpler than constrained optimization. \n",
    "\n",
    "The penalty function approach basically tries to approximate a latter problem by a former one. \n",
    "\n",
    "Consider first the constraint minimization problem above, without inequality constraints.\n",
    "\n",
    "The quadratic penalty function $Q(x;\\mu)$ is defined as\n",
    "\n",
    "$$ Q(x;\\mu) = f(x) + \\frac{\\mu}{2} \\sum_{i\\in \\mathcal{E}} \\left(c_i(x)\\right)^2, $$\n",
    "\n",
    "where $mu>0$ is the penalty parameter.\n",
    "\n",
    "What we expect is that a minimizer of $Q$ given $\\mu$ converges to a solution to the original constrained problem as $\\mu \\uparrow \\infty$. \n",
    "\n",
    "When inequaility constraints exist, one can define $Q$ as\n",
    "\n",
    "$$ Q(x;\\mu) = f(x) + \\frac{\\mu}{2} \\sum_{i\\in \\mathcal{E}} \\left(c_i(x)\\right)^2 + \\frac{\\mu}{2}\\sum_{i\\in\\mathcal{I}}\\left(\\max\\{0,-c_i(x)\\}\\right)^2. $$\n",
    "\n",
    "Instead of a quadratic function, one may use the absolute value $|.|$ (the $l^1$-penalty function).\n",
    "\n",
    "There is a problem, however. As $\\mu$ tends to infinity, the Hessian of $Q$ becomes ill-conditioned (some eigenvalues grow with $\\mu$), which makes the calculation of the Newton step less accurate. In the Augmented Lagrangian method $\\mu$ does not have to grow indefinitely, and this problem is less severe. \n",
    "\n",
    "### Augmented Lagrangian method\n",
    "\n",
    "For simplicity, consider again the problem without inequality constraints. The augmented Lagrangian is defined as \n",
    "\n",
    "$$ \\mathcal{L}_A(x;\\lambda,\\mu) = f(x) -\\sum_{i\\in\\mathcal{E}}\\lambda_ic_i(x)  + \\frac{\\mu}{2} \\sum_{i\\in \\mathcal{E}} \\left(c_i(x)\\right)^2.$$\n",
    "\n",
    "I.e. we augment the Lagrangian with the quadratic penalty function. Again, to minimize $\\mathcal{L}_A$ with respect to $x$ for given $(\\lambda,\\mu)$ only requires unconstrained minimization routines (possibly with ones that solve problems with the bound constraints). \n",
    "\n",
    "Theoretically it is shown that, if $\\lambda = \\lambda^*$ (true multiplier), then there is a threshold $\\overline{\\mu}$ such that, for all $\\mu \\ge \\overline{\\mu}$, a minimizer of $\\mathcal{L}_A$ is $x^*$, a solution to the original problem. \n",
    "\n",
    "In practice, we do not know true $\\lambda^*$. The method threfore also specifies how the estimate of $\\lambda$, as well as $x$ and $\\mu$, is updated as we iterate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Active set methods and interior point methods\n",
    "\n",
    "The biggest difficulty in dealing with inequality constraints is that we do not know a priori which constraints bind and which do not, and that we need to figure out which ones are active/binding. \n",
    "\n",
    "Active set methods make educated guess about which inequality constraints are going to bind/be active, and keep updating the guess along iteration. \n",
    "\n",
    "Interior point methods, or barrier methods, take a different approach. They alter the problem so that inequality constraints are always satisfied with strict inequalities (i.e. we are always in the, sort of, interior of the constraint set). \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^N, \\{s_i\\}_{i \\in \\mathcal{I} } } f(x) - \\mu\\sum_{i\\in \\mathcal{I}} \\log s_i $$\n",
    "\n",
    "subject to\n",
    "\n",
    "\n",
    "1. Equality constraints: for $i\\in \\mathcal{E}$, $ c_i(x) = 0$, and\n",
    "\n",
    "2. Inequality constraints: for $i\\in \\mathcal{I}$, $c_i(x) - s_i \\le 0$.\n",
    "\n",
    "for some $\\mu>0$. \n",
    "\n",
    "$\\{s_i\\}_{i\\in \\mathcal{I}}$ are called slack variables. The structure of the above problem implies that its solution satisfies $s_i>0$ for all $i$.\n",
    "\n",
    "The basic idea is to consider a sequence $\\{\\mu_k\\}$ that converges to zero, and to generate a solution to the above problem $\\{x_k\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz\n",
    "## 1. \n",
    "\n",
    "Suppose we want to solve\n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^N} f(x)$$\n",
    "\n",
    "subject only to the bound constraints:\n",
    "\n",
    "$$ lb_i \\le x_i \\le ub_i $$\n",
    "\n",
    "for $i=1,2,...,N$. \n",
    "\n",
    "Which methods can we use in _scipy.optimize.minimize()_ to solve this problem? \n",
    "\n",
    "Hint: In the documentation <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html>, click on (See here) next to the method names to check whether each method takes \"bounds\" as input. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "In _scipy.optimize.minimize()_, we need to specify the set of constraints as a dictionary or a sequence of dictionaries. \n",
    "\n",
    "Read the \"The Dictionary Data Type\" and \"Dictionaries vs. Lists\" sections in <https://automatetheboringstuff.com/chapter5/> and answer Practice Questions Q1-Q4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \n",
    "\n",
    "_scipy.optimize.minimize()_ function returns an _OptimizeResult_ object that contains a lot of useful information. \n",
    "\n",
    "In the lecture notebook, we have assigned the result to the variable _res_ as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = optimize.minimize(func, [-1.0,1.0], args=(-1.0,), jac=func_deriv, method='SLSQP',\n",
    "                        options={'disp': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How do we know whether an algorithm has ended successfully or not? \n",
    "\n",
    "Hint: In the lecture we have displayed a solution by executing: _print(res.x)_ \n",
    "\n",
    "Hint: Read the \"Attributes\" section in <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html> to see whether there are any attributes that tell you whether an algorithm has finished successfully.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "The Simplex Algorithm is the most popular method to sove the linear programming problem <https://en.wikipedia.org/wiki/Simplex_algorithm>. Explain the algorithm briefly."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
